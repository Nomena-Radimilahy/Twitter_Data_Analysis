---
title: "Erster Blick auf den Twitter-Datensatz"
author: "Nomena Radimilahy"
date: "2023-08-05"
output: 
  pdf_document:
    latex_engine: xelatex
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE)
```

## 1. Vorbereitungen

```{r}
# Laden der benötigten Bibliothek
suppressPackageStartupMessages({
  library(lubridate)
  library(dplyr)
  
})

```

Zunächst importieren wir die benötigten Bibliotheken und anschließend den Datensatz.

```{r}
# Datensatz einlesen
twitter <- read.csv("C:/Users/nomen/OneDrive/Desktop/Bachelorarbeit/Datenanalyse/twitter_data.csv", sep = ",", header = T, stringsAsFactors = T)
```

Da wir uns für die Periode nach dem Veröffentlichen interessieren, wollen wir nur die Daten ab dem 30.November 2022 in dem Datensatz haben.

```{r}
# Konvertieren der Spalte "CreatedAt" in ein Datumsformat
twitter$CreatedAt <- as.POSIXct(twitter$CreatedAt, format = "%Y-%m-%d %H:%M:%S")

# Filtern der Daten
twitter <- twitter %>%
  filter(CreatedAt >= as.POSIXct("2022-11-30 00:00:00") & CreatedAt <= as.POSIXct("2023-02-06 23:59:59"))
```

Werfen wir nun einen Blick auf die Struktur des Datensatzes.


```{r}
#twitter[3:5, ] # weil Emojis in Latex nicht geschrieben werden können
str(twitter)

```

Der Datensatz enthält insgesamt 40 Variablen. Der Struktur zeigt die Anwesenheit von Fehlwerte, daher werden wir zunächst um die Fehlwerte kümmern. 


## 2. Überprüfung der Vollständigkeit

Identifizieren wir nun die expliziten und implizite Fehlwerte.


```{r}
# explizite Fehlwerte
colSums((is.na(twitter)))

```

```{r}
# implizite Fehlwerte
sapply(twitter, function(x) sum(x %in% c("", " ", "NA", "N/A", "unknown", "Not Available")))

```

Die Variablen "Source" und "UserLang" weisen ausschließlich explizite Fehlwerte auf und sind daher für diese Studie irrelevant. Die Variablen, die mit "Ir" beginnen, beinhalten Informationen, die mit 'Retweets' und 'Replies' in Zusammenhang stehen. Unsere Studie fokussiert sich hauptsächlich auf die von Nutzern verfassten Texte, wodurch Informationen über Retweets, wie die Retweet-IDs, für die Sentiment- und Themenanalyse unerheblich sind. Daher werden alle Variablen, die mit "Ir" anfangen, außer Acht gelassen. Dies betrifft insgesamt 20 Variablen. Weiterhin liefern die Variablen "UserUrl", "UserProfileImageUrl", "IsoLanguageCode", "IsReplyToStatusId", "UserId", "UserCreatedAt", "UserLang", "UserName", "UserScreenName" und "UserDescription" keine relevanten Informationen für die Sentimentanalyse, da wir uns primär für die geäußerten Meinungen und nicht für die Eigenschaften der User interessieren. Diese werden daher ebenfalls vernachlässigt. Dies reduziert die Anzahl der zu berücksichtigenden Variablen auf 8. Die Fehlwerte befanden sich alle in den nun vernachlässigten Variablen, daher müssen keine weiteren Fehlwerte behandelt werden.

Die Daten ohne Fehlwerte werden in einem neuen Objekt gespeichert.


```{r}
twitter_clean <- data.frame(Id = twitter$Id, CreatedAt = twitter$CreatedAt, RetweetCount = twitter$RetweetCount, FavoriteCount...LikeCount = twitter$FavoriteCount...LikeCount, Text = twitter$Text, UserFollowersCount = twitter$UserFollowersCount, UserFriendsCount = twitter$UserFriendsCount, UserVerified = twitter$UserVerified)

```

Nun möchten wir die Retweets aus unserem Datensatz entfernen. Retweets sind in der Regel Duplikate von Originaltweets, und ihre Anwesenheit kann zu überflüssigen Wiederholungen führen. Durch das Entfernen von Retweets wird die Analyse, insbesondere in Bereichen wie Textanalyse oder Sentiment-Analyse, bei denen die Originalität des Inhalts von Bedeutung ist, vereinfacht. Typischerweise beginnen Retweets mit "RT", gefolgt vom Benutzernamen des ursprünglichen Verfassers und dem Inhalt des Originaltweets. 


```{r}
twitter_clean <- twitter_clean[!startsWith(as.character(twitter_clean$Text), "RT"), ]

```

```{r}
# Set the display options to show full numeric values
options(scipen = 999)
str(twitter_clean)
#View(twitter_clean)
```

Für unsere Analyse haben wir nun 52016 und 8 Variablen übrig. 


## 3. Datenbereinigung

Die Variable "Text" enthält die Tweets, die analysiert werden sollen, und muss zunächst vorverarbeitet werden. Inhalte wie Hashtags, Emojis oder Nutzererwähnungen können das Modell beeinträchtigen und sollten daher zuerst entfernt werden. Die Bereinigung wird in Python vorgenommen. Um den Import in Python zu vereinfachen, wird der DataFrame als CSV-Datei gespeichert.

```{r}
# Write the data frame to a CSV file
write.csv(twitter_clean, file = "C:/Users/nomen/OneDrive/Desktop/Bachelorarbeit/Datenanalyse/twitter_clean.csv", row.names = FALSE)
```
